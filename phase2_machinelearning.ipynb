{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Mushrooms\n",
    "### Machine Learning Phase II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parvi Verma\n",
    "#### s3744398\n",
    "#### Pranav Karambelkar\n",
    "#### s3715015\n",
    "#### June 9, 2019\n",
    "\n",
    "## Objective:\n",
    "The main objective of this investigation is to solve the binary classfication problem of classifying mushrooms as edible or poisonous. This project consists of two phases: In Phase I, Data Preparation and Data Exploration was covered and Phase II is focused on fitting three Machine Learning Algorithms to solve the Binary Classification problem.\n",
    "\n",
    "## Source:\n",
    "Source of the dataset is as follows\n",
    "1. Parent Source: www.kaggle.com\n",
    "2. Link: https://www.kaggle.com/uciml/mushroom-classification/version/1\n",
    "3. The dataset was originally contributed to the UCI Machine Learning repository.\n",
    "4. Time Period: Donated to UCI ML 27th April 1987\n",
    "5. Link for UCI: https://archive.ics.uci.edu/ml/datasets/Mushroom\n",
    "\n",
    "## Dataset:\n",
    "This dataset is collected from The Audubon Society Field\n",
    "Guide to North American Mushrooms in 1981 and sourced by UCI Machine Learning Repository. The dataset consists of 8124 observations and 23 features out which 22 are Descriptive features and 1 Target feature with two classes denoted by `e` as `edible mushrooms` and `p` as `poisonous mushrooms`. All the features in this dataset are categorical including the target feature.\n",
    "\n",
    "## Methodology:\n",
    "Three Classifiers are used to classify the labels of target feature:\n",
    "\n",
    "1) K-Nearest Neighbor\n",
    "\n",
    "2) Decision Tree\n",
    "\n",
    "3) Gaussian Naive Bayes\n",
    "\n",
    "The modeling strategy begins by loading the preprocessed data from phase I and gaining insights about the data. Then the dataset was partitioned into set of descriptive features and target feature. In next step, The binary target feature was encoded into 0 for poisonous mushrooms and 1 for edible mushrooms. Further the descriptive features were one-hot-encoded. For ease of analysis, 5000 observations are randomly sampled out and then the data was split on 70-30 split.\n",
    "\n",
    "Before fitting any classifier on train data,10 most important features were selected with help of RFI feature selection technique. This was done because our data was giving 100% accuracy with 1-nearest neighbor classifier which implies that full set of features was leading to overfitting and hence it was a necessary requirement for this dataset to apply feature selection.\n",
    "\n",
    "Using the selected features hyperparameter tuning on K-Nearest Neighbors, Decision trees and Gaussian Naive Bayes was done using training data, we conducted a 5-fold cross-validation with 3 repeatitions. Furthermore, we conducted a 5-fold cross-validation on the test data and performed a paired t-test to check for if performance difference was statistically significant. The compare the performance of each classfier on the basis of accuracy, Confusion matrix, precision, F1-score and recall.\n",
    "\n",
    "## Insights gained from Phase I:\n",
    "In phase I,Through the preparaion of data it was noted that there were no inconsistencies in the dataset and the featues were renamed, and re-arranged for ease of analysis. Features like `‘veil-type’`, `‘stalk-surface-below-ring’` and `‘stalk-color-below-ring’` were removed on the basis of redundancy and insignificance. Through the exploration of data it was noted that the this is a balanced dataset with almost equal number of observations in both the classes with no specific feature dividing the target feature into two pure homogeneous groups.\n",
    "\n",
    "## Loading Dataset from Phase I:\n",
    "As Phase I was done in R, therefore the prepared filed is exported in .csv format and loaded into Jupiter Notebook directory. The dataset contains 8124 observations and 20 features out which 19 are Descriptive Features and 1 Target Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>stalk-root</th>\n",
       "      <th>stalk-surface-above-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>convex</td>\n",
       "      <td>smooth</td>\n",
       "      <td>brown</td>\n",
       "      <td>yes</td>\n",
       "      <td>pungent</td>\n",
       "      <td>free</td>\n",
       "      <td>close</td>\n",
       "      <td>narrow</td>\n",
       "      <td>black</td>\n",
       "      <td>enlarging</td>\n",
       "      <td>equal</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>pendant</td>\n",
       "      <td>black</td>\n",
       "      <td>scattered</td>\n",
       "      <td>urban</td>\n",
       "      <td>poisonous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>convex</td>\n",
       "      <td>smooth</td>\n",
       "      <td>yellow</td>\n",
       "      <td>yes</td>\n",
       "      <td>almond</td>\n",
       "      <td>free</td>\n",
       "      <td>close</td>\n",
       "      <td>broad</td>\n",
       "      <td>black</td>\n",
       "      <td>enlarging</td>\n",
       "      <td>club</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>pendant</td>\n",
       "      <td>brown</td>\n",
       "      <td>numerous</td>\n",
       "      <td>grasses</td>\n",
       "      <td>edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bell</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>yes</td>\n",
       "      <td>anise</td>\n",
       "      <td>free</td>\n",
       "      <td>close</td>\n",
       "      <td>broad</td>\n",
       "      <td>brown</td>\n",
       "      <td>enlarging</td>\n",
       "      <td>club</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>pendant</td>\n",
       "      <td>brown</td>\n",
       "      <td>numerous</td>\n",
       "      <td>meadows</td>\n",
       "      <td>edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>convex</td>\n",
       "      <td>scaly</td>\n",
       "      <td>white</td>\n",
       "      <td>yes</td>\n",
       "      <td>pungent</td>\n",
       "      <td>free</td>\n",
       "      <td>close</td>\n",
       "      <td>narrow</td>\n",
       "      <td>brown</td>\n",
       "      <td>enlarging</td>\n",
       "      <td>equal</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>pendant</td>\n",
       "      <td>black</td>\n",
       "      <td>scattered</td>\n",
       "      <td>urban</td>\n",
       "      <td>poisonous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>convex</td>\n",
       "      <td>smooth</td>\n",
       "      <td>grey</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>crowded</td>\n",
       "      <td>broad</td>\n",
       "      <td>black</td>\n",
       "      <td>tapering</td>\n",
       "      <td>equal</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>evanescent</td>\n",
       "      <td>brown</td>\n",
       "      <td>abundant</td>\n",
       "      <td>grasses</td>\n",
       "      <td>edible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap-shape cap-surface cap-color bruises     odor gill-attachment  \\\n",
       "0    convex      smooth     brown     yes  pungent            free   \n",
       "1    convex      smooth    yellow     yes   almond            free   \n",
       "2      bell      smooth     white     yes    anise            free   \n",
       "3    convex       scaly     white     yes  pungent            free   \n",
       "4    convex      smooth      grey      no     none            free   \n",
       "\n",
       "  gill-spacing gill-size gill-color stalk-shape stalk-root  \\\n",
       "0        close    narrow      black   enlarging      equal   \n",
       "1        close     broad      black   enlarging       club   \n",
       "2        close     broad      brown   enlarging       club   \n",
       "3        close    narrow      brown   enlarging      equal   \n",
       "4      crowded     broad      black    tapering      equal   \n",
       "\n",
       "  stalk-surface-above-ring stalk-color-above-ring veil-color ring-number  \\\n",
       "0                   smooth                  white      white         one   \n",
       "1                   smooth                  white      white         one   \n",
       "2                   smooth                  white      white         one   \n",
       "3                   smooth                  white      white         one   \n",
       "4                   smooth                  white      white         one   \n",
       "\n",
       "    ring-type spore-print-color population  habitat     target  \n",
       "0     pendant             black  scattered    urban  poisonous  \n",
       "1     pendant             brown   numerous  grasses     edible  \n",
       "2     pendant             brown   numerous  meadows     edible  \n",
       "3     pendant             black  scattered    urban  poisonous  \n",
       "4  evanescent             brown   abundant  grasses     edible  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mush.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning Dataset:\n",
    "The dataset is partitioned into 'Data' containing all the Descriptive features and 'target' containing the Target Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Partitioning Dataset \n",
    "#Set of Descriptive Features \n",
    "Data = mush.drop(columns = 'target')\n",
    "#Target Feature\n",
    "target = mush['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Target Feature:\n",
    "Before carrying out modeling on the dataset, it is necessary to encode all the categorical features including target feature. \n",
    "Using sklearn, the target feature is label-encoded into 0 and 1 where `0` depicting `poisonous mushrooms` and `1` depicting `edible mushrooms`. As function labelEncoder() encodes the data as 0 and 1 in an alphabetical order of labels, therefore replacing `0` with `1` and `1` with `0` in order to correctly label the positive class of our dataset as `1` which is `edible mushrooms` and negative class as `0` which is `poisonous mushrooms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([4208, 3916], dtype=int64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Encoding Target Feature\n",
    "## 1 = edible, 0 = poisonous \n",
    "from sklearn import preprocessing\n",
    "\n",
    "target = preprocessing.LabelEncoder().fit_transform(target)\n",
    "np.unique(target, return_counts = True)\n",
    "## as alphabetically it is edible=0 and poisonous = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([3916, 4208], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## replacing it with edible = 1 and poisonous = 0\n",
    "target_encoded = pd.Series(target).replace({1: 0, 0: 1}).values\n",
    "target_encoded\n",
    "np.unique(target_encoded, return_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, edible becomes 1 and poisonous becomes 0 after replacing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot-Encoding Nominal Features: \n",
    "This type encoding technique does not assume any arithmetic relationship between different classes. As all the features are nominal descriptive features, therefore one-hot Encoding each nominal Decriptive feature.\n",
    "\n",
    "Creating list of all the columns with nominal values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cap-shape',\n",
       " 'cap-surface',\n",
       " 'cap-color',\n",
       " 'bruises',\n",
       " 'odor',\n",
       " 'gill-attachment',\n",
       " 'gill-spacing',\n",
       " 'gill-size',\n",
       " 'gill-color',\n",
       " 'stalk-shape',\n",
       " 'stalk-root',\n",
       " 'stalk-surface-above-ring',\n",
       " 'stalk-color-above-ring',\n",
       " 'veil-color',\n",
       " 'ring-number',\n",
       " 'ring-type',\n",
       " 'spore-print-color',\n",
       " 'population',\n",
       " 'habitat']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## One-Hot-Encoding Descriptive Features \n",
    "#Data = pd.DataFrame(data=data)\n",
    "# getting the list of all the categorical descriptive features\n",
    "categorical_cols = Data.columns[Data.dtypes==object].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using get_dummies() method, One-Hot Encoding all the nominal descriptive features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.get_dummies(Data, columns=['cap-shape'])\n",
    "Data = pd.get_dummies(Data, columns=['cap-surface'])\n",
    "Data = pd.get_dummies(Data, columns=['cap-color'])\n",
    "Data = pd.get_dummies(Data, columns=['bruises'])\n",
    "Data = pd.get_dummies(Data, columns=['odor'])\n",
    "Data = pd.get_dummies(Data, columns=['gill-attachment'])\n",
    "Data = pd.get_dummies(Data, columns=['gill-spacing'])\n",
    "Data = pd.get_dummies(Data, columns=['gill-size'])\n",
    "Data = pd.get_dummies(Data, columns=['gill-color'])\n",
    "Data = pd.get_dummies(Data, columns=['stalk-shape'])\n",
    "Data = pd.get_dummies(Data, columns=['stalk-root'])\n",
    "Data = pd.get_dummies(Data, columns=['stalk-surface-above-ring'])\n",
    "Data = pd.get_dummies(Data, columns=['stalk-color-above-ring'])\n",
    "Data = pd.get_dummies(Data, columns=['veil-color'])\n",
    "Data = pd.get_dummies(Data, columns=['ring-number'])\n",
    "Data = pd.get_dummies(Data, columns=['ring-type'])\n",
    "Data = pd.get_dummies(Data, columns=['spore-print-color'])\n",
    "Data = pd.get_dummies(Data, columns=['population'])\n",
    "Data = pd.get_dummies(Data, columns=['habitat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After one-hot encoding, there are 103 descriptive features in the dataset 'Data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape_bell</th>\n",
       "      <th>cap-shape_conical</th>\n",
       "      <th>cap-shape_convex</th>\n",
       "      <th>cap-shape_flat</th>\n",
       "      <th>cap-shape_knobbed</th>\n",
       "      <th>cap-shape_sunken</th>\n",
       "      <th>cap-surface_fibrous</th>\n",
       "      <th>cap-surface_grooves</th>\n",
       "      <th>cap-surface_scaly</th>\n",
       "      <th>cap-surface_smooth</th>\n",
       "      <th>...</th>\n",
       "      <th>population_scattered</th>\n",
       "      <th>population_several</th>\n",
       "      <th>population_solitary</th>\n",
       "      <th>habitat_grasses</th>\n",
       "      <th>habitat_leaves</th>\n",
       "      <th>habitat_meadows</th>\n",
       "      <th>habitat_paths</th>\n",
       "      <th>habitat_urban</th>\n",
       "      <th>habitat_waste</th>\n",
       "      <th>habitat_woods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-shape_bell  cap-shape_conical  cap-shape_convex  cap-shape_flat  \\\n",
       "0               0                  0                 1               0   \n",
       "1               0                  0                 1               0   \n",
       "2               1                  0                 0               0   \n",
       "3               0                  0                 1               0   \n",
       "4               0                  0                 1               0   \n",
       "\n",
       "   cap-shape_knobbed  cap-shape_sunken  cap-surface_fibrous  \\\n",
       "0                  0                 0                    0   \n",
       "1                  0                 0                    0   \n",
       "2                  0                 0                    0   \n",
       "3                  0                 0                    0   \n",
       "4                  0                 0                    0   \n",
       "\n",
       "   cap-surface_grooves  cap-surface_scaly  cap-surface_smooth      ...        \\\n",
       "0                    0                  0                   1      ...         \n",
       "1                    0                  0                   1      ...         \n",
       "2                    0                  0                   1      ...         \n",
       "3                    0                  1                   0      ...         \n",
       "4                    0                  0                   1      ...         \n",
       "\n",
       "   population_scattered  population_several  population_solitary  \\\n",
       "0                     1                   0                    0   \n",
       "1                     0                   0                    0   \n",
       "2                     0                   0                    0   \n",
       "3                     1                   0                    0   \n",
       "4                     0                   0                    0   \n",
       "\n",
       "   habitat_grasses  habitat_leaves  habitat_meadows  habitat_paths  \\\n",
       "0                0               0                0              0   \n",
       "1                1               0                0              0   \n",
       "2                0               0                1              0   \n",
       "3                0               0                0              0   \n",
       "4                1               0                0              0   \n",
       "\n",
       "   habitat_urban  habitat_waste  habitat_woods  \n",
       "0              1              0              0  \n",
       "1              0              0              0  \n",
       "2              0              0              0  \n",
       "3              1              0              0  \n",
       "4              0              0              0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling:\n",
    "As our data does not have any numerical features therefore scaling is not applied here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Observations:\n",
    "For ease of analysis only 5000 observations are randomly sampled out. 'Data_sample' and 'target_sample' are two sets created after randomly selecting small subset out of entire data.\n",
    "\n",
    "The function `sample()` in `pandas` is used for randomly selecting 5000 observation. To pick same set of observations in both `Data_sample` and `target_sample` sets, the value for random state is set to be same.\n",
    "\n",
    "Here both datasets are converted into `pandas` data frame, on which `sample()` function in pandas is applied and using the `values` method, both sets are converted back to `NumPy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "(5000L, 103L)\n",
      "(5000L, 1L)\n"
     ]
    }
   ],
   "source": [
    "Data_sample = pd.DataFrame(Data).sample(n=5000, random_state=8).values\n",
    "target_sample = pd.DataFrame(target_encoded).sample(n=5000, random_state=8).values\n",
    "print(type(Data_sample))\n",
    "print(type(target_sample))\n",
    "print(Data_sample.shape)\n",
    "print(target_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split:\n",
    "The Data_sample and target_sample datasets with 5000 observations are split under 70:30 split ratio, 70% of data is train data and 30% is test data where train data is used to train the model and test data is used by learnt model to correctly predict the labels and evaluate the performance and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D_train, D_test, t_train, t_test = train_test_split(Data_sample, \n",
    "                                                    target_sample, \n",
    "                                                    test_size = 0.3,\n",
    "                                                    random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "K-fold Cross Validation is used on entire dataset where entire dataset is divided into K equal-sized partitions and at every iteration a chunk of data is taken as test dataset and rest k-1 chunks are taken as train dataset.\n",
    "Here 5-fold Cross Validation is applied with help of `RepeatedStratifiedKFold function` imported from sklearn.model_selection which randomly splits the data into 5 equal-sized chunks and repeats for 3 times.\n",
    "Further this cross validation method is used within cross_val_score() function in sklearn.model_selection to find the the mean cross-validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "                                     n_repeats=3,\n",
    "                                     random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of KNN with Full Set of Features:\n",
    "Using 1 nearest neighbor classifier with 5-fold cross validation and 3 repetitions where cross validation is applied with help of cross_val_score() function in sklearn.model_selection. \n",
    "The mean performance accuracy with full set of features is found to be 100% which implies that full set of features is leading to overfitting and hence it is a necessary requirement for this dataset to apply feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "cv_results_full = cross_val_score(estimator=clf,\n",
    "                             X=Data_sample,\n",
    "                             y=target_sample, \n",
    "                             cv=cv_method, \n",
    "                             scoring='accuracy')\n",
    "cv_results_full\n",
    "cv_results_full.mean().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: Random Forest Importance\n",
    "Random Forest Importance is one of the most powerful techniques for feature selection. This technique is selected for this report because RFI(as filter method) works independent of any Machine learning algorithms and selects the most important set of features by considering interaction between all descriptive features and target feature.\n",
    "Here to look upon 10 most important features, RFI is applied over full dataset. \n",
    "\n",
    "Performing Random Forest Importance Feature selection technique using 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['odor_none', 'odor_foul', 'stalk-surface-above-ring_silky',\n",
       "       'gill-size_broad', 'gill-size_narrow',\n",
       "       'spore-print-color_chocolate', 'bruises_no', 'bruises_yes',\n",
       "       'ring-type_pendant', 'gill-color_buff'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn import feature_selection as fs\n",
    "\n",
    "## Random Forest\n",
    "num_features = 10\n",
    "model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "model_rfi.fit(Data_sample, target_sample)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n",
    "best_features_rfi = Data.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21210606, 0.07361107, 0.06309581, 0.05159904, 0.04684217,\n",
       "       0.0383101 , 0.03102275, 0.02717501, 0.02682927, 0.02373116])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n",
    "feature_importances_rfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the 10 best features selected by RFI with their importance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pos = np.arange(len(best_features_rfi))\n",
    "plt.bar(y_pos,feature_importances_rfi, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, best_features_rfi, rotation = 90)\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Random Forest: Selected important feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "### K Nearest Neighbor (KNN)\n",
    "In Hyperparameter tuning for KNN, we define a set of parameters and model for grid search.\n",
    "Parameters for Hyperparameter Tuning of KNN are as follows:\n",
    "* k : number of nearest neighbors\n",
    "* p : distance metric\n",
    "\n",
    "Here values for k is considered from 1 to 7 and values for p as `1(Manhattan), 2(Euclidean) and 5(Minkowski)`. \n",
    "Next, these set of parameters and KNeighborsClassifier() as model are passed into GridSearchCV() function with cross validation method discussed above and roc_auc as scoring metric.\n",
    "Here roc_auc is used as scoring metric because it is robust to imbalanced dataset where negative class dominates positive class.Though our data is balanced but to make the classifier robust against all types of dataset this is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KNN \n",
    "params_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7], \n",
    "              'p': [1, 2, 5]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "gs_KNN = GridSearchCV(estimator=KNeighborsClassifier(), \n",
    "                      param_grid=params_KNN, \n",
    "                      cv=cv_method,\n",
    "                      verbose=1,  # verbose: the higher, the more messages\n",
    "                      scoring='roc_auc', \n",
    "                      return_train_score=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fitting grid search KNN on selected set of 10 features by RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 21 candidates, totalling 315 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for K-Nearest Neighbor\n",
      "{'n_neighbors': 7, 'p': 1}\n",
      "\n",
      "Best Score for K-Nearest Neighbor\n",
      "0.9899128601159204\n",
      "\n",
      " Grid Search Results for  K-Nearest Neighbor\n",
      "    n_neighbors  p  test_score     metric\n",
      "0             1  1    0.965176  Manhattan\n",
      "1             1  2    0.965176  Euclidean\n",
      "2             1  5    0.965176  Minkowski\n",
      "3             2  1    0.977164  Manhattan\n",
      "4             2  2    0.977164  Euclidean\n",
      "5             2  5    0.977164  Minkowski\n",
      "6             3  1    0.981388  Manhattan\n",
      "7             3  2    0.981388  Euclidean\n",
      "8             3  5    0.981388  Minkowski\n",
      "9             4  1    0.988483  Manhattan\n",
      "10            4  2    0.988483  Euclidean\n",
      "11            4  5    0.988483  Minkowski\n",
      "12            5  1    0.989534  Manhattan\n",
      "13            5  2    0.989534  Euclidean\n",
      "14            5  5    0.989534  Minkowski\n",
      "15            6  1    0.989579  Manhattan\n",
      "16            6  2    0.989579  Euclidean\n",
      "17            6  5    0.989579  Minkowski\n",
      "18            7  1    0.989913  Manhattan\n",
      "19            7  2    0.989913  Euclidean\n",
      "20            7  5    0.989913  Minkowski\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 315 out of 315 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "## fitting hyperparameter tuning on to selected features\n",
    "gs_KNN.fit(D_train[:, fs_indices_rfi], t_train);\n",
    "print(\"\\nBest Parameters for K-Nearest Neighbor\") \n",
    "print(gs_KNN.best_params_)\n",
    "print(\"\\nBest Score for K-Nearest Neighbor\")\n",
    "print(gs_KNN.best_score_)\n",
    "gs_KNN.cv_results_['mean_test_score']\n",
    "results_KNN = pd.DataFrame(gs_KNN.cv_results_['params'])\n",
    "results_KNN['test_score'] = gs_KNN.cv_results_['mean_test_score']\n",
    "results_KNN['metric'] = results_KNN['p'].replace([1,2,5], [\"Manhattan\", \"Euclidean\", \"Minkowski\"])\n",
    "print(\"\\n Grid Search Results for  K-Nearest Neighbor\")\n",
    "print(results_KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5-fold stratified cross validation with 3 repetitions, We observe that the best parameters for KNN are found to be k = 7 and p = 1 (Manhattan distance metric).The mean AUC score with the best parameters is found to be 0.9899.\n",
    "\n",
    "Plotting the Grid Search Result for each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN Performance Comparison\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd374f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nKNN Performance Comparison\")\n",
    "df_knn = results_KNN.pivot(index='n_neighbors',columns='metric',values='test_score')\n",
    "df_knn.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot confirms that k = 7 with the Manhattan distance metric p = 1 performs the best out of all other combinations. As the values for test-score was same for all three p-values for each k, therefore the plot shows superimposed lines for all three distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (DT)\n",
    "In Hyperparameter tuning for DT, we perform a grid search on parameters. The Parameters for Hyperparameter Tuning of DT are as follows:\n",
    "\n",
    "criterion : includes criterion such as Gini Index and Entropy\n",
    "\n",
    "maximum depth: integer metric\n",
    "\n",
    "min_samples_split : The minimum number of samples needed to split an internal node\n",
    "\n",
    "Here the criterion are taken as Gini and Entropy. The gini index and Entropy would give us a probability of an object being classified to a particular class, where the least possible value considered as ideal for the root node. The maximum depth can take any integer value as well as none and we have used it up to 8. The min samples split has been used with its default value of 2. Next, these set of parameters are passed into GridSearchCV() function with cross validation method discussed above and roc_auc as scoring metric.\n",
    "Here roc_auc is used as scoring metric because it is robust to imbalanced dataset where negative class dominates positive class.Though our data is balanced but to make the classifier robust against all types of dataset this is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "df_classifier = DecisionTreeClassifier(random_state=999)\n",
    "params_DT = {'criterion': ['gini', 'entropy'],\n",
    "             'max_depth': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "             'min_samples_split': [2]}\n",
    "gs_DT = GridSearchCV(estimator=df_classifier, \n",
    "                     param_grid=params_DT, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fitting grid search DT on selected set of 10 features by RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 16 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for Decision Tree\n",
      "{'min_samples_split': 2, 'criterion': 'gini', 'max_depth': 6}\n",
      "\n",
      "Best Score for Decision Tree\n",
      "0.9947373447460229\n",
      "\n",
      "Grid Search Results for Decision Tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 240 out of 240 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gini</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.889920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gini</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gini</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gini</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gini</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gini</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gini</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gini</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>entropy</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.889920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entropy</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entropy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.984343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entropy</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.993606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>entropy</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>entropy</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>entropy</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entropy</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.994737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   criterion  max_depth  min_samples_split  test_score\n",
       "0       gini          1                  2    0.889920\n",
       "1       gini          2                  2    0.972829\n",
       "2       gini          3                  2    0.984343\n",
       "3       gini          4                  2    0.993606\n",
       "4       gini          5                  2    0.994101\n",
       "5       gini          6                  2    0.994737\n",
       "6       gini          7                  2    0.994737\n",
       "7       gini          8                  2    0.994737\n",
       "8    entropy          1                  2    0.889920\n",
       "9    entropy          2                  2    0.972829\n",
       "10   entropy          3                  2    0.984343\n",
       "11   entropy          4                  2    0.993606\n",
       "12   entropy          5                  2    0.994101\n",
       "13   entropy          6                  2    0.994737\n",
       "14   entropy          7                  2    0.994737\n",
       "15   entropy          8                  2    0.994737"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_DT.fit(D_train[:, fs_indices_rfi], t_train);\n",
    "print(\"\\nBest Parameters for Decision Tree\") \n",
    "print(gs_DT.best_params_)\n",
    "print(\"\\nBest Score for Decision Tree\")\n",
    "print(gs_DT.best_score_)\n",
    "print(\"\\nGrid Search Results for Decision Tree\") \n",
    "results_DT = pd.DataFrame(gs_DT.cv_results_['params'])\n",
    "results_DT['test_score'] = gs_DT.cv_results_['mean_test_score']\n",
    "results_DT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5-fold stratified cross validation with 3 repetitions, We observe that the best parameters for DT are found to be criterion = gini , min_samples_split = 2 and max_depth = 6 .The mean AUC score with the best parameters is found to be 0.9947.\n",
    "\n",
    "Plotting the Grid Search Result for each iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DT Performance Comparison\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xdd41a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nDT Performance Comparison\")\n",
    "df_dt = results_DT.pivot(index='max_depth',columns='criterion',values='test_score')\n",
    "df_dt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot confirms that criterion = gini , min_samples_split = 2 and max_depth = 6 performs the best out of all other combinations. As the values for test-score was same for gini index and entropy for each max_depth, therefore the plot shows superimposed lines for gini index and entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Gaussian Naive Bayes (NB)\n",
    "In hyperparameter tuning of NB, we perform grid search on parameter var_smoothing. The parameter for variance smoothing specifies the largest variance in all features to be added to variances for calculating stability.\n",
    "\n",
    "The Gaussian NB assumes that all the descriptive features are normally distributed. Since, it is highly unlikely in practice, we perform transformation using PowerTransformer, by defining a random variable with a mean of 2 and sample 1000 numbers.\n",
    "Here roc_auc is used as scoring metric because it is robust to imbalanced dataset where negative class dominates positive class.Though our data is balanced but to make the classifier robust against all types of dataset this is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x distribution\n",
      "342 -0.276524  transformed\n",
      "321  3.216755  exponential\n",
      "247  1.297923  transformed\n",
      "514 -1.678249  transformed\n",
      "343  0.204341  exponential\n",
      "386  0.486638  exponential\n",
      "304  0.883091  exponential\n",
      "772  0.015391  exponential\n",
      "889  0.184597  transformed\n",
      "554  0.076667  exponential\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "np.random.seed(999)\n",
    "sample_size = 1000\n",
    "x_exponential = np.random.exponential(2, sample_size).reshape(-1, 1)\n",
    "x_transformed = PowerTransformer().fit_transform(x_exponential)\n",
    "df1 = pd.DataFrame(x_exponential)\n",
    "df1['distribution'] = 'exponential'\n",
    "df2 = pd.DataFrame(x_transformed)\n",
    "df2['distribution'] = 'transformed'\n",
    "# combine the two data frames into one to be used for plotting\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df.rename(columns={0: 'x'}, inplace=True)\n",
    "print(df.sample(n=10))\n",
    "np.logspace(0,-9, num=10)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "np.random.seed(999)\n",
    "nb_classifier = GaussianNB()\n",
    "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "gs_NB = GridSearchCV(estimator=nb_classifier, \n",
    "                     param_grid=params_NB, \n",
    "                     cv=cv_method,\n",
    "                     verbose=1, \n",
    "                     scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fitting grid search NB on selected set of 10 features by RFI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 100 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Parameters for Naive Bayes\n",
      "{'var_smoothing': 2.310129700083158e-08}\n",
      "\n",
      "Best Score for Naive Bayes\n",
      "0.9858735196398886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1500 out of 1500 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_smoothing</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.981737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657933</td>\n",
       "      <td>0.981769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.533670</td>\n",
       "      <td>0.981948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.432876</td>\n",
       "      <td>0.982159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var_smoothing  test_score\n",
       "0       1.000000    0.981212\n",
       "1       0.811131    0.981737\n",
       "2       0.657933    0.981769\n",
       "3       0.533670    0.981948\n",
       "4       0.432876    0.982159"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_transformed = PowerTransformer().fit_transform(D_train[:, fs_indices_rfi])\n",
    "gs_NB.fit(Data_transformed, t_train);\n",
    "print(\"\\nBest Parameters for Naive Bayes\") \n",
    "print(gs_NB.best_params_)\n",
    "print(\"\\nBest Score for Naive Bayes\") \n",
    "print(gs_NB.best_score_)\n",
    "results_NB = pd.DataFrame(gs_NB.cv_results_['params'])\n",
    "results_NB['test_score'] = gs_NB.cv_results_['mean_test_score']\n",
    "results_NB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5-fold stratified cross validation with 3 repetitions, We observe that the best parameters for NB is found to be var_smoothing = 2.310129700083158e-08 .The mean AUC score with the best parameters is found to be 0.9858."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparision\n",
    "The three classifier has been optimized above with help of training dataset and now we optimize these classfiers with help of test data using the cross validation which is itself a random process.Further pairWise t-test is performed in order to understand any difference between the performance of any two optimized classifiers is statistically significant. We first, perform 5-fold stratified cross-validation on each best model (without any repetitions). Second, we conduct a paired t-test for the AUC score between the following model combinations:\n",
    "\n",
    "* K Nearest-Neighbor vs Naive Bayes\n",
    "* K Nearest-Neighbor vs Decision Tree\n",
    "* Decision Tree vs Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_method_ttest = RepeatedStratifiedKFold(n_splits=5,  \n",
    "                                random_state=999)\n",
    "cv_results_KNN = cross_val_score(estimator=gs_KNN.best_estimator_,\n",
    "                                 X=D_test[:, fs_indices_rfi],\n",
    "                                 y=t_test, \n",
    "                                 cv=cv_method_ttest, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n",
    "cv_results_KNN.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_DT = cross_val_score(estimator=gs_DT.best_estimator_,\n",
    "                                 X=D_test[:, fs_indices_rfi],\n",
    "                                 y=t_test, \n",
    "                                 cv=cv_method_ttest, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n",
    "cv_results_DT.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.986"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_transformed = PowerTransformer().fit_transform(D_test[:, fs_indices_rfi])\n",
    "\n",
    "cv_results_NB = cross_val_score(estimator=gs_NB.best_estimator_,\n",
    "                                 X=D_transformed,\n",
    "                                 y=t_test, \n",
    "                                 cv=cv_method_ttest, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n",
    "cv_results_NB.mean().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=10.199961217916917, pvalue=1.0390609078022574e-13)\n",
      "Ttest_relResult(statistic=10.717641417229473, pvalue=1.9183115165146602e-14)\n",
      "Ttest_relResult(statistic=12.069948932284488, pvalue=2.7289532094084873e-16)\n"
     ]
    }
   ],
   "source": [
    "## t-test\n",
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_rel(cv_results_KNN, cv_results_NB))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_KNN))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_NB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the p-values are less than 0.05 which indicates a statistically significant difference. Looking at these results, we conclude that at a 95% significance level. On the basis of this test DT is statistically the best model out of all other models (in terms of AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis \n",
    "All three classfiers with best parameters have been applied over the train data. Now these learnt classfiers predict the target labels for test data.To compare the performance of these three classifiers, the predicted labels for test data are compared to original labels for test data.\n",
    "\n",
    "Following Performance Evaluation creterion are used:\n",
    "* Accuracy\n",
    "* Confusion Matrix\n",
    "* F1-Score\n",
    "* Precision\n",
    "* Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "On the basis of Accuracy it can be said that DT outperforms both KNN and NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for K-Nearest Neighbor\n",
      "0.9626666666666667\n",
      "\n",
      "Accuracy for Decision Tree\n",
      "0.978\n",
      "\n",
      "Accuracy for Naive Bayes\n",
      "0.48\n"
     ]
    }
   ],
   "source": [
    "## KNN \n",
    "KNN_pred = gs_KNN.predict(D_test[:, fs_indices_rfi])\n",
    "from sklearn import metrics\n",
    "print(\"\\nAccuracy for K-Nearest Neighbor\") \n",
    "print(metrics.accuracy_score(t_test, KNN_pred))\n",
    "##DT\n",
    "DT_pred = gs_DT.predict(D_test[:, fs_indices_rfi])\n",
    "print(\"\\nAccuracy for Decision Tree\") \n",
    "print(metrics.accuracy_score(t_test, DT_pred))\n",
    "##NB\n",
    "NB_transformed = PowerTransformer().fit_transform(D_test[:, fs_indices_rfi])\n",
    "NB_pred = gs_NB.predict(NB_transformed)\n",
    "print(\"\\nAccuracy for Naive Bayes\") \n",
    "print(metrics.accuracy_score(t_test, NB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "* KNN : The Confusion matrix depicts the outcome for test data where 0 is depicted as poisonous mushrooms and 1 as edible mushrooms. The matrix suggests that 664 labels were correctly classified as poisonous mushrooms whereas 56 labels were mislabelled as edible mushrooms. The matrix also suggests that 780 labels were correctly classified as edible mushrooms whereas 0 labels were mislabelled as poisonous mushrooms. \n",
    "* DT : The Confusion matrix depicts the outcome for test data where 0 is depicted as poisonous mushrooms and 1 as edible mushrooms. The matrix suggests that 707 labels were correctly classified as poisonous mushrooms whereas 20 labels were mislabelled as edible mushrooms. The matrix also suggests that 760 labels were correctly classified as edible mushrooms whereas 13 labels were mislabelled as poisonous mushrooms. \n",
    "* NB : The Confusion matrix depicts the outcome for test data where 0 is depicted as poisonous mushrooms and 1 as edible mushrooms. The matrix suggests that 720 labels were correctly classified as poisonous mushrooms whereas 780 labels were mislabelled as edible mushrooms. The matrix also suggests that 0 labels were correctly classified as edible mushrooms whereas 0 labels were mislabelled as poisonous mushrooms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion matrix for K-Nearest Neighbor\n",
      "[[664  56]\n",
      " [  0 780]]\n",
      "\n",
      "Confusion matrix for Decision Tree\n",
      "[[707  13]\n",
      " [ 20 760]]\n",
      "\n",
      "Confusion matrix for Naive Bayes\n",
      "[[720   0]\n",
      " [780   0]]\n"
     ]
    }
   ],
   "source": [
    "##KNN\n",
    "print(\"\\nConfusion matrix for K-Nearest Neighbor\") \n",
    "print(metrics.confusion_matrix(t_test, KNN_pred))\n",
    "##DT\n",
    "print(\"\\nConfusion matrix for Decision Tree\") \n",
    "print(metrics.confusion_matrix(t_test, DT_pred))\n",
    "##NB\n",
    "print(\"\\nConfusion matrix for Naive Bayes\") \n",
    "print(metrics.confusion_matrix(t_test, NB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score, precision, recall\n",
    "* Precision: The percentage of edible mushrooms prediction that are truly edible mushrooms. On the basis of Precision for positive class that is edible(1) it can be said that DT outperforms both KNN and NB . \n",
    "\n",
    "* Recall: The percentage of edible mushrooms predictions that were correctly labelled as edible mushrooms. On the basis of Recall for positive class that is edible(1) it can be said that KNN outperforms both DT and NB . \n",
    "\n",
    "* F1-Score: It is the harmonic mean of Precision and Recall. On the basis of F1-Score for positive class that is edible(1) it can be said that DT outperforms both KNN and NB.\n",
    "\n",
    "`From above analysis, we can deduce that DT is the best classifier on basis of F1-score which is weighted average of both precision and recall. As our objective is to minimize mushrooms which were falsely classified as edible but actually are poisonous.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report for K-Nearest Neighbor\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       720\n",
      "           1       0.93      1.00      0.97       780\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1500\n",
      "   macro avg       0.97      0.96      0.96      1500\n",
      "weighted avg       0.97      0.96      0.96      1500\n",
      "\n",
      "\n",
      "Classification report for Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       720\n",
      "           1       0.98      0.97      0.98       780\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1500\n",
      "   macro avg       0.98      0.98      0.98      1500\n",
      "weighted avg       0.98      0.98      0.98      1500\n",
      "\n",
      "\n",
      "Classification report for Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65       720\n",
      "           1       0.00      0.00      0.00       780\n",
      "\n",
      "   micro avg       0.48      0.48      0.48      1500\n",
      "   macro avg       0.24      0.50      0.32      1500\n",
      "weighted avg       0.23      0.48      0.31      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##KNN\n",
    "print(\"\\nClassification report for K-Nearest Neighbor\") \n",
    "print(metrics.classification_report(t_test, KNN_pred))\n",
    "##DT\n",
    "print(\"\\nClassification report for Decision Tree\") \n",
    "print(metrics.classification_report(t_test, DT_pred))\n",
    "##NB\n",
    "print(\"\\nClassification report for Naive Bayes\") \n",
    "print(metrics.classification_report(t_test, NB_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations and Proposed Solutions:\n",
    "* The main limitations in our modeling strategy is that the dataset with full set of features is giving 100% accuracy which is implies overfitting or data leakage. In depth analysis can be done to rectify this problem.\n",
    "\n",
    "* Feature Selection is done only with help of one technique RFI. Furthermore, other feature selection techniques and depth analysis on feature selection can be done.\n",
    "\n",
    "* A small subset of dataset was taken in account for ease of analysis but with given set of hardware and equipments, full dataset can be analyised properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "The Decision Tree Classifier with 10 most important features selected by Random Forest Importance(RFI) produces highest cross-validated AUC score on the training data. The Decision Tree model, when evaluated on the test set, also outperformed both Naive Bayes and K-Nearest Neighbor models with respect to AUC. Moreover, we observed that, the models are highly sensitive to the number of features as full set of features leads to 100% accuracy, which in turn, leads to over fitting. Hence, it is seemingly appropriate that, working with 10 most features results in models that are easier to train and understand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1.  John D. Kelleher, Brian Mac Namee, Aoife D’Arcy : FUNDAMENTALS OF MACHINE LEARNING FOR PREDICTIVE\n",
    "DATA ANALYTICS- Algorithms, Worked Examples, and Case Studies, 2015. (Sections 1, 4.2.1, 4.2.2)\n",
    "\n",
    "2. Aurélien Géron : Hands-On Machine Learning with Scikit-Learn and TensorFlow- Concepts, Tools, and Techniques to Build Intelligent Systems, 2017. (Section I.6, I.7)\n",
    "\n",
    "3. Wes McKinney: Python for Data Analysis - Data Wrangling with Pandas, NumPy, and IPython, 2018. (Section 1.3, 1.4, 2.2.2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
